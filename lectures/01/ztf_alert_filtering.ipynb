{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129c3684",
   "metadata": {},
   "source": [
    "# Finding rare astronomical objects in the ZTF public alert stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f0f99",
   "metadata": {},
   "source": [
    "Notebook created by Theophile du Laz (tdulaz@caltech.edu)\n",
    "\n",
    "Heavily inspired by last year's summer school - excellent - exercises from:\n",
    "- Robert Stein\n",
    "- Igor Andreoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e05ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086a25e",
   "metadata": {},
   "source": [
    "### Loading up the data\n",
    "\n",
    "Here, we'll look at an arbitrary night of ZTF data, and see what we can find. Instead of having all of you query a public ZTF alert broker for a full night of data (that could take some time, and would require some additional code to format things nicely), we have provided a full night of ZTF data in the `data` directory. You should find 3 files:\n",
    "* ztf_alerts_2460474.5.parquet\n",
    "* ztf_alerts_2460474.5_prv_candidates.parquet\n",
    "\n",
    "**ztf_alerts_2460474.5.parquet:**\n",
    "\n",
    "The first file contains the alerts themselves, in a flattened format we will discuss in a dedicated sections. Some fields that would take a lot of space and that are not needed for this analysis have been removed, like the images and some other string-based fields that we do not need.\n",
    "\n",
    "**ztf_alerts_2460474.5_prv_candidates.parquet:**\n",
    "\n",
    "This file contains the aggregated previous candidates for each alert. Meaning that for a given objectId, we merged the prv_candidates from all of its alerts (not just those from that night). To keep the amount of data manageable, we:\n",
    "* only kept up to 6 months of ZTF data, which is more than enough for this purpose.\n",
    "* we excluded the lightcurves of objects which alerts had low drb scores. We will apply the same score for filtering out bogus alerts anyway, so this should not be a problem.\n",
    "\n",
    "If you want to recover the lightcurve of a given alert, you can simply look for the rows in this dataset with the same objectId, and then apply a cut on the JD to make sure that you are not \"cheating\" by looking into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684a9f6",
   "metadata": {},
   "source": [
    "#### Loading the alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9638420",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_path = \"./ztfsummerschool_alert_data/ztf_alerts_2460474.5.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(alerts_path):\n",
    "    print(f\"ERROR: No file found at {alerts_path}. Make sure to download the data first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alerts = pd.read_parquet(alerts_path)\n",
    "print(f\"Loaded {len(df_alerts)} alerts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b42217",
   "metadata": {},
   "source": [
    "The alerts come as a dataframe, where each row is a flattened ZTF alert packet without:\n",
    "* cutouts\n",
    "* prv_candidates\n",
    "* fp_hists\n",
    "* some of the string fields that we don't need for this analysis\n",
    "\n",
    "by flattened, I mean that the real alert packets have this structure:\n",
    "```\n",
    "{\n",
    "    \"objectId\": \"ZTF18abvpirw\",\n",
    "    \"candid\": 1102223222815015016,\n",
    "    \"candidate\": {\n",
    "        \"jd\": 2458658.7223229,\n",
    "        \"fid\": 1,\n",
    "        \"pid\": 1102223222815,\n",
    "        \"diffmaglim\": 20.5,\n",
    "        \"programid\": 1,\n",
    "        \"candid\": 1102223222815015016,\n",
    "        \"isdiffpos\": \"t\",\n",
    "        \"tblid\": 1,\n",
    "        \"nid\": 1102,\n",
    "        \"rcid\": 28,\n",
    "        \"field\": 762,\n",
    "        \"ra\": 0.0,\n",
    "        \"dec\": 0.0,\n",
    "        \"magpsf\": 18.0,\n",
    "        ...\n",
    "    },\n",
    "}\n",
    "```\n",
    "but here since it's a dataframe, it's flattened to look like this:\n",
    "```\n",
    "{\n",
    "    \"objectId\": \"ZTF18abvpirw\",\n",
    "    \"candid\": 1102223222815015016,\n",
    "    \"candidate.jd\": 2458658.7223229,\n",
    "    \"candidate.fid\": 1,\n",
    "    \"candidate.pid\": 1102223222815,\n",
    "    \"candidate.diffmaglim\": 20.5,\n",
    "    \"candidate.programid\": 1,\n",
    "    \"candidate.candid\": 1102223222815015016,\n",
    "    \"candidate.isdiffpos\": \"t\",\n",
    "    \"candidate.tblid\": 1,\n",
    "    \"candidate.nid\": 1102,\n",
    "    \"candidate.rcid\": 28,\n",
    "    \"candidate.field\": 762,\n",
    "    \"candidate.ra\": 0.0,\n",
    "    \"candidate.dec\": 0.0,\n",
    "    \"candidate.magpsf\": 18.0,\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This ZTF data contains {len(df_alerts)} different alerts, which {len(df_alerts['objectId'].unique())} are unique objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539803e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objectIds are attributed to detections with a spatial proximity\n",
    "# detections are new positons create new objectIds, and subsequent detections at\n",
    "# the same position are associated with the same objectId\n",
    "# this is how we keep track of the same object over time, to build lightcurves\n",
    "print(f\"5 random objects: {df_alerts['objectId'].sample(5).values}\")\n",
    "\n",
    "# alerts also come with a unique alert identifier, the candid\n",
    "# the candid is unique for each alert, and is used to identify the alert\n",
    "# in the ZTF database\n",
    "print(f\"5 random candid: {df_alerts['candidate.candid'].sample(5).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab5ba7",
   "metadata": {},
   "source": [
    "#### Loading the prv_candidates/lightcurves:\n",
    "\n",
    "*This file is on the larger side, so it might take a couple of seconds to load.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_path = \"./ztfsummerschool_alert_data/ztf_alerts_2460474.5_prv_candidates.parquet\"\n",
    "\n",
    "if not os.path.isfile(lightcurve_path):\n",
    "    print(f\"ERROR: No file found at {lightcurve_path}. Make sure to download the data first!\")\n",
    "\n",
    "df_lightcurve = pd.read_parquet(lightcurve_path)\n",
    "\n",
    "# the objectId was set as an index here, but we can reset it to have it as a column which\n",
    "# will be easier to work with\n",
    "df_lightcurve.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lightcurve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can look for a specific object's lightcurve using the objectId column from the alerts, that are used as the index in the lightcurve data\n",
    "df_lightcurve[df_lightcurve['objectId'] == 'ZTF24aarwzgs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5ee60",
   "metadata": {},
   "source": [
    "let's write a function that given an alert, returns the lightcurve of the associated object. That is, all the previous detections and non-detections (up to a year) of the object, to which we will apply a cut on the JD to make sure we are not cheating by looking into the future, and then concatenate it with the alert itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lightcurve(alert):\n",
    "    prv_candidates = df_lightcurve[df_lightcurve[\"objectId\"] == alert[\"objectId\"]]\n",
    "    prv_candidates = prv_candidates[prv_candidates[\"jd\"] < alert[\"candidate.jd\"]]\n",
    "    # before concatenating the alert, we need to format it the same way as the prv_candidates\n",
    "    # that is, remove the \"candidate.\" prefix from the column names\n",
    "    alert_copy = alert.copy()\n",
    "    alert_copy = {\n",
    "        key.replace(\"candidate.\", \"\"): value\n",
    "        for key, value in alert_copy.items()\n",
    "    }\n",
    "    # remove the classifications. and coordinates. fields\n",
    "    alert_copy = {key: value for key, value in alert_copy.items() if not key.startswith(\"classifications.\") and not key.startswith(\"coordinates.\")}\n",
    "    prv_candidates = pd.concat([prv_candidates, pd.DataFrame([alert_copy])])\n",
    "    return prv_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3791aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it here:\n",
    "alert = df_alerts[df_alerts[\"objectId\"] == \"ZTF24aarwzgs\"].iloc[0]\n",
    "lc = get_lightcurve(alert)\n",
    "lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e805d9",
   "metadata": {},
   "source": [
    "great, now let's plot the lightcurve of an alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfe81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid2color = {1: \"green\", 2: \"red\", 3: \"orange\"}\n",
    "fid2filter = {1: \"ztfg\", 2: \"ztfr\", 3: \"ztfi\"}\n",
    "\n",
    "def plot_lightcurve(lc, nondet=True):\n",
    "    # add a \"xaxis\" column to the lightcurve = jd - jd.min()\n",
    "    lc[\"xaxis\"] = lc[\"jd\"] - lc[\"jd\"].min() if nondet else lc[\"jd\"] - lc[lc[\"magpsf\"] > 0][\"jd\"].min()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fid, color in fid2color.items():\n",
    "        lc_fid = lc[lc[\"fid\"] == fid]\n",
    "        if len(lc_fid) == 0:\n",
    "            continue\n",
    "        # then we split detections and non-detections (no magpsf)\n",
    "        mask_det = lc_fid[\"magpsf\"] > 0\n",
    "        lc_det = lc_fid[mask_det]\n",
    "        lc_nondet = lc_fid[~mask_det]\n",
    "        if len(lc_det) > 0:\n",
    "            plt.errorbar(lc_det[\"xaxis\"], lc_det[\"magpsf\"], yerr=lc_det[\"sigmapsf\"], fmt='o', color=color, label=fid2filter[fid])\n",
    "        if len(lc_nondet) > 0 and nondet:\n",
    "            plt.scatter(lc_nondet[\"xaxis\"], lc_nondet[\"diffmaglim\"], color=color, marker='v', alpha=0.5)\n",
    "    plt.gca().invert_yaxis() # lower magnitude is brighter (reverse the y-axis)\n",
    "    plt.xlabel(\"Time (JD)\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.title(f\"Lightcurve for {lc.iloc[0]['objectId']} at JD {lc.iloc[0]['jd']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it here:\n",
    "lc = get_lightcurve( df_alerts[df_alerts[\"objectId\"] == \"ZTF24aarwzgs\"].iloc[0])\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98008bae",
   "metadata": {},
   "source": [
    "This one has only 1 alert which is the only detection, so not much to go on. Let's look at another one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af7d46",
   "metadata": {},
   "source": [
    "# Analysing a single source\n",
    "Let's look more closely at one of these sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67028f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alerts[df_alerts[\"objectId\"] == \"ZTF24aambaia\"].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df722165",
   "metadata": {},
   "source": [
    "We have a lot of high-level information, for example:\n",
    "    \n",
    "- The `drb` (Deep Real/Bogus) score tells us how likely a source is to be real rather than an image artifact. \n",
    "- The `ra`/`dec` values tell us where a candidate is on the sky\n",
    "- The `isdiffpos` field tells us if the source is brighter in this image than in the reference image. For most transient that is true, but for variable stars it can be false, as their magnitude likely varies up and down around an average value, which is what the reference image captures (as it is a stack of many images through long periods of time).\n",
    "- The `magpsf` field is the magnitude of the source as measured by the point spread function (PSF) photometry. This is the most common way to measure the brightness of a source in astronomical images. The lower the value, the brighter the source.\n",
    "- The `sigmapsf` field is the uncertainty on the `magpsf` measurement. The lower the value, the more certain we are of the brightness measurement.\n",
    "- The `distpsnr1` field is the distance to the nearest PS1 source. This is useful to identify if a source is a known object or not.\n",
    "- The `sgscore1` field is the output of a ML classifier that tells us how likely the closest PS1 source is to be a single star, or a galaxy. This is useful to identify if a source can be resolved as a star or not.\n",
    "- The \"classifications\" fields are the output of ML-classifiers we run in the Kowalski broker, and add to every alert to \"enrich\" them. They are not perfect, but these phenomenological classifiers can be useful to look for hosted transients using acai_h score for example. You can learn more about these classifiers here: https://wandb.ai/dimaduev/acai/reports/Classification-of-astrophysical-events-with-ACAI--VmlldzoxMTkwNjYx\n",
    "- The coordinates field can be ignored in this analysis for the most part, though `l` & `b` are galactic coordinates, that you could use to look for sources in/outside the galactic plane for example.\n",
    "...\n",
    "\n",
    "*There are many more fields in the alert packet, but these are the most relevant for this analysis. You can refer to the full [ZTF alert schema](https://zwickytransientfacility.github.io/ztf-avro-alert/schema.html) if needed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b378b4",
   "metadata": {},
   "source": [
    "##### Let's plot this object's lightcurve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae791cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = get_lightcurve(df_alerts[df_alerts[\"objectId\"] == \"ZTF24aambaia\"].iloc[0])\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8912b",
   "metadata": {},
   "source": [
    "This one is interesting! It has been detected multiple times in both R and G bands. This is likely a \"transient\". It does not have a long history of being detected, so is unlikely to be a \"variable\" object.\n",
    "\n",
    "We can see that it clearly reaches a peak, and then fades pretty slowly. We also notice that it rises and fades at a different rate in r-band (red) and g-band (green). Many astronomical transients have emission that can be described as a blackbody. Hotter blackbodies appear \"blue\", cooler ones appear \"red\". So the lightcurve is telling us that the source starts off somewhat hot (with g-band a little bit brighter than r-band), but then as its magnitude fades, it gets \"redder\" (red is brighter than blue here, and fades more slowly). Its \"color\" is getting redder. This is a common feature of supernovae for example, so that could be a good guess for what this object is. We can't be sure without taking additional data (an optical spectrum) though.\n",
    "\n",
    "This is precisely the kind of objects that programs such as the Bright Transient Survey look for. The goal of the analysis is to come up with ways to find these interesting objects in the 100k+ alerts that ZTF produces every night (in public data stream, the full stream is much larger and harder to deal with). We have enough resources to get spectra for a few objects (maybe dozen per night with SEDM), but certainly not all a hundred thousand. So, we need to identify all the interesting transients in the ZTF data programmatically, review the interesting ones manually, and assign follow-up resources to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194906d2",
   "metadata": {},
   "source": [
    "# Finding the needles in the haystack\n",
    "How can we narrow down the large number of sources?\n",
    "\n",
    "In general, our data will contain the following categories of object:\n",
    "    \n",
    "- Image artifacts\n",
    "- Solar system objects\n",
    "- Stars\n",
    "- Active Galactic Nuclei\n",
    "- Transients\n",
    "    \n",
    "Your goal is to separate the sources into these five categories. There's no one right answer, but let me give you some tips for how I would do it. You can check the solution notebook for a more complete illustration.\n",
    "\n",
    "### Image Artifacts\n",
    "Image artifacts can be best-identified by a well-trained human eye, looking at both raw images and image subtractions. Even an untrained human eye is pretty good at this, you're just looking for something Gaussian-like. However, it would be INSANE for a human to look through 150k different images and identify image artifacts. Instead, ZTF provides a human-eye-approximation, in the form of a neural network (a machine-learning algorithm) thatassigns a score for detections based on whether they look \"real\" or \"bogus\". 1=definitely real, 0=definitely bogus. \n",
    "\n",
    "**I suggest that you look at a histogram of \"drb\" scores from the sources. For the purpose of this analysis, we'll simply use 0.5 (as this is also what we used when retrieving the full lightcurves).**\n",
    "\n",
    "### Solar System Objects\n",
    "Solar system objects (asteroids, comets, minor planets, satellites) are objects in our solar system. They are charateised by their distinctive feature: unlike distant stars and galaxies, SSOs will move noticeably over the duration of a night. ZTF detections are based on position on the sky. \n",
    "\n",
    "**Requiring that an object was detected at least twice in total, in the same position, with a separation of 15 minutes is an excellent way to filter our SSOs.**\n",
    "\n",
    "*Reminder: you should only count detections (entries in \"prv_candidates\" with \"magpsf\"), but NOT count non-detections. Also, don't forget to include the most recent detection (\"candidate\") and add it to the historical detections (\"prv_candidates\").*\n",
    "\n",
    "However, we also have other information in the alert packet that can help us identify SSOs. For example, the `ssdistnr` field tells us the distance to the nearest known solar system object. If this is small, it is likely that the object is a solar system object. So, we can also filter out objects with `ssdistnr` lower than say `10\"`, and with a reasonable magnitude range (say `10 < ssmagnr < 20`).\n",
    "\n",
    "\n",
    "### Stars\n",
    "Stars can often be identified via the morphology. The PanSTARRS survey is a deeper survey than ZTF, with a catalogue of a billion sources. Machine learning has been used to assign a \"Star/Galaxy\" score to each of these (1=Star, 0=galaxy, see https://arxiv.org/abs/1902.01935 for more info). ZTF data is cross-matched to these, and the closest three panstarrs sources are included in the alert. The alert includes the magnitudes in g and r (sgmag1/sgmag2/sgmag3), and the star/galaxy score (sgscore1/2/3), for the three nearest sources. The distance to each is provided too (distpsnr1/2/3, in units or arseconds). \n",
    "\n",
    "**I would suggest that you make a list of sgscores. Loop over each ZTF source, and add the sgscore of the nearest panstarrs source to your list (that's 'sgscore1'). Make a histogram of these values, and decide where you want to make a cut. Remember, a high sgscore means a source is probably a star! Unlike step 1, where you wanted high drb scores, here we want LOW sgscores.**\n",
    "\n",
    "**Once you have decided on an sgscore cut, then you should use that to select likely stars. You should loop over each ZTF source, and check the distance to the nearest panstarrs source. If that distance is <3 arcseconds, and the sgscore is less than your threshold, you the source is probably a star.**\n",
    "\n",
    "### AGN\n",
    "Active Galactic Nucleii (AGN) are objects that vary in time. Unlike transients, which typically rise and then fall, AGN will often be detected many times over a long period of time. They might not vary very much.\n",
    "\n",
    "By this point, you should not have many candidates left (e.g I had ~50 sources left). At this point you should start doing human inspection. The easiest way to distinguish AGN/non-AGN is by eye. \n",
    "\n",
    "My rule of thumb:\n",
    "\n",
    "-If there is some indication of a steady rise and/or fall, it is a 'Probable Transient'. \n",
    "\n",
    "-If it detected a couple of times within a short timespan of a couple of days, it is a 'Possible Transient'.\n",
    "\n",
    "-If it is detected in at two different time clusters without evolving much, then you cannot rule out some rise and fall that went in the gap. However, it is unlikely. I would categorise this as 'Probable AGN'. \n",
    "\n",
    "-If something is detected many times without a single rapid rise+fall, then it is a 'Definite AGN'. It can either evolve super slowly over thousands of days, or vary both up and down.\n",
    "\n",
    "As you might realise, my \"rule of thumb\" is biased, as we are looking for transients and NOT AGNs. We clearly do not have enough information here to classify something as an AGN, but it is enough for us to know that something is not a transient.\n",
    "\n",
    "Below is an example of each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253cc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Probable transient (our trusty supernova from earlier)\n",
    "# You can always confirm a SN classification (if it was made public) \n",
    "# by looking it up on the Transient Name Server (TNS): https://www.wis-tns.org/\n",
    "# There you can search by RA and Dec.Here for example, it's https://www.wis-tns.org/object/2024hyh\n",
    "# and it does have an SN designation, and has been discovered by BTSbot, presented to you earlier this morning,\n",
    "# and classified as an SN Ia at redshift z=0.045 by the ZTF team as well.\n",
    "lc = get_lightcurve(df_alerts[df_alerts[\"objectId\"] == \"ZTF24aambaia\"].iloc[0])\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa1bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Another possible Transient, though we do not have enough data to be sure, and the detections are quite close\n",
    "lc = get_lightcurve(df_alerts[df_alerts[\"objectId\"] == \"ZTF24aarxkvo\"].iloc[0])\n",
    "plot_lightcurve(lc, nondet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86925bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probable AGN\n",
    "lc = get_lightcurve(df_alerts[df_alerts[\"objectId\"] == \"ZTF18abvijql\"].iloc[0])\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85366e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible star that shows some variability, though in a real world scenario we would look at the entire ZTF lightcurve (since 2018)\n",
    "# to look for periodicity and other patterns\n",
    "lc = get_lightcurve(df_alerts[df_alerts[\"objectId\"] == \"ZTF18abcwyrm\"].iloc[0])\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331f499",
   "metadata": {},
   "source": [
    "If you want to move beyond \"scanning\" manually for candidates, you can also look for arcchival detections in https://ned.ipac.caltech.edu/. AGN will often be in catalogues, such as https://heasarc.gsfc.nasa.gov/W3Browse/all/milliquas.html. If somethingf is in Milliquas, it's probaby an AGN. If not, it might still be an AGN.\n",
    "\n",
    "However, I think the lightcurves can already give you a strong hint. I would suggest you discuss difficult cases with your fellow students. This is what we do in the real world, too! A second (third, or fifth) opinion is always helpful. Also, you can look at a transient on a public broker like Alerce: https://alerce.online/object/ZTF19acudhum. That will help you visualize the entire lightcurve, helpful to distinguish AGN and variable stars from say supernovae."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a3ac2",
   "metadata": {},
   "source": [
    "#### Exercise: look for fast evolving transients\n",
    "\n",
    "##### Step 1: \n",
    "Now, you have a good understanding of how to:\n",
    "- remove image artifacts using the drb score\n",
    "- remove solar system objects using the number of detections (with a separation of 15 minutes) and/or the ssdistnr + ssmagnr fields\n",
    "- remove stars using the distpsnr1/2/3, sgscore1/2/3 fields (hint, just using the sgscore1 + distpsnr1 is enough most of the time)\n",
    "- optional: rely on the acai scores to look for hosted or nuclear transients (though keep in mind those are ML classifiers and not perfect)\n",
    "- look for AGN or variable stars (long-lived objects, detected often) using the lightcurve information, or fields such as the `ndethist` (number of detections in the past) and `ncovhist` (number of coverages in the past, includes non-detections), and `jdstarthist` (Julian date of the first ever detection).\n",
    "\n",
    "This should be enough to remove most things that are not genuine transients, and leave you with a handful of interesting candidates. However you'll still be left with a large amount of objects, and for the sake of this analysis we would like you to focus on the fast evolving transients. \n",
    "\n",
    "These are very objects, that rise to a peak and fall in brightness over a short period of time. We would definitely like to follow up on these, especially if they evolve faster than your \"typical\" supernova.\n",
    "\n",
    "So, **one more step for you to implement is to try to compute the rate at which said transients are rising or fading, and filter out those that are not evolving quickly enough.**\n",
    "\n",
    " - *Hint 1: for a given transient, you can try to identify a peak, and compute rise and fade rates independently.*\n",
    " - *Hint 2: You can use some of the fields in the alert packet or the lightcurve itself t compute the `age` of the transient. Useful to filter out older objects and focus on younger ones.*\n",
    " - *Hint 3: If you have enough data, you can use the \"color\" as an information to look for interesting objects, it could be that some objects in this dataset are rising/fading faster in one band than the other, which could be a sign of a peculiar transient.*\n",
    "*Hint 4: We chose a night where we know there is at least 1 fast evolving transient, try to find it!*\n",
    "\n",
    "##### Step 2:\n",
    "We would like you to plot each object. Ideally, you would plot the lightcurve of each object, and maybe some additional information that you think is relevant. Additional information could be features from the alert packet, or custom features that you computed. Also, in a real-world scenario, you would definitely want to see the images of the objects, but we don't provide them here. However, once you filter out the uninsteresting objects, you should be left with a small enough number of objects to inspect them manually. Just like for visualizing the full lightcurve, you can retrieve the images from Alerce: https://alerce.online/object/ZTF19acudhum. You will see that under each image, there is a link formatted in a way that you can retrieve any alert's cutout provided you know the `candid` from the alert packet. Also, if you want to go the extra mile, you can try to retrieve the full lightcurve from Alerce as well, or any other public broker that provides ZTF data (like [Fink](https://fink-portal.org/api), which API service is great for these kind of tasks). To query both Alerce and Fink, you can use the `requests` library in python, and the `json` module to parse the responses if necessary. When downloading the cutouts, Alerce will return them in their original format, which is a `gzip` compressed `fits` file. You can use the `astropy` library to open these files and display the images. You can find an example of how we do this in Kowalski [here](https://github.com/skyportal/kowalski/blob/c8b836e3b93fe81a964feca8105857b81f8f8db0/kowalski/tools/update_ztf_thumbnails_fritz.py#L56-L107). It should be pretty straightforward to adapt this code to your needs. A nice plot could have the 3 images on top of each other on the left, the lightcurve on the right, and some extra metadata on top or at the bottom.\n",
    "\n",
    "\n",
    "##### Step 3: \n",
    "When you done with the filtering and the visualization, we'd like you to rank each object by how interesting you think it is (essentially, prioritize for which object you think we should get a spectrum first). Feel free to implement any ranking system you think is appropriate, manual inspection is also a valid way to rank objects, often the best way to do it. Which is why a strict filter is important, so you don't end up with too many objects to inspect manually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
